---
title: "CLI"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F)
library(tidyverse)
library(readxl)
library(DT)
#install.packages("remotes")
#remotes::install_github("rstudio/fontawesome")
library(fontawesome)

f <- "./static/commands.xlsx"
```

---

# Operating System Commands

## General
[SS64](https://ss64.com/)<br>
Reference guide containing syntax and examples for the most prevalent computing commands (Database and Operating System).<br>

## Windows

### CMD
[Microsoft Docs](https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/cmd)<br>
Command line syntax

**Syntax**: `cmd [/c|/k] [/s] [/q] [/d] [/a|/u] [/t:{<b><f> | <f>}] [/e:{on | off}] [/f:{on | off}] [/v:{on | off}] [<string>]`

**Multiple commands**: `"<command1>&&<command2>&&<command3>"`

#### Parameters
```{r cmd, echo=F}
t1 <- read_excel(f, sheet="windows-commands")
# Show all rows in table (no pagination)
datatable(t1, options=list(paging=FALSE), rownames=F)
```

### Powershell 

<div style="display:inline;">`r fa("hard-hat")` `r fa("hammer")` Under construction...</div>

---

## Linux

### Commands
```{r}
t2 <- read_excel(f, sheet="linux-commands")
# Show all rows in table (no pagination)
datatable(t2, options=list(paging=FALSE), rownames=F)
```

### File System
```{r, echo=F}
t3 <- read_excel(f, sheet="linux-filesystem")
# Show all rows in table (no pagination)
datatable(t3, options=list(paging=FALSE), rownames=F)
```

### Permissions

General syntax: `_rwxrwxrwx 1 owner group`<br>

`_ | rwx | rwx | rwx` <Special><Owner><Group><All Users>

`r` = Read<br>
`w` = Write<br>
`x` = Execute

`chown` = Change ownership<br>
`chmod` = Change permissions<br>

`sudo chown <user>:<group> <file>`

`sudo chown 664 <file>`

### Package Manager
```{r, echo=F}
t4 <- read_excel(f, sheet="linux-packages")
# Show all rows in table (no pagination)
datatable(t4, options=list(paging=FALSE), rownames=F)
```


### Server Setup
Initial Linux server setup on Digital Ocean

1) Login to server as root
2) `$ adduser <username>`
  a. Creates new admin user
  Add user to sudo group: `usermod -aG sudo <username>`
3) `$ exit`
4) Reload SSH connection
5) Login as new user
6) `$ sudo vi /etc/ssh/sshd_config`
  a. Configuration fo rputty/incoming SSH connections
  b. Change `PermitRootLogin` to `no`
7) `$ sudo reboot`
8) On boot, can see linux kernel used for current build/image
  a. `GNU/Linux 5.4.0-51-generic`
9) `$ apt list --upgradable`
10) `$ sudo apt upgrade`
11) `$ uname -a`
  a. Shows system info
  b. Even though you updated the kernel, need to reboot to take effect
12) `$ sudo reboot`
13) `$ sudo apt update`
	a. Just to be sure 
14) `$ sudo apt upgrade`
15) `$ ufw`
	a. *Uncomplicated firewall
16) `$ sudo ufw status verbose`
	a. Shows firewall status
17) `$ sudo ufw help`
18) `$ sudo ufw allow OpenSSH`
	a. Will allow opening of ports
19) `$ sudo ufw enable`
	a. Turns on firewall
20) `$ sudo ufw status verbose`
  a. Shows status of firewall/open ports
21) Good time for snapshot backup
	a. Has to be shutdown for backup/snapshot
22) `$ sudo shutdown -h now`
You have to go to DigitalOcean and reboot


**Connect to machine via ssh: `ssh <username>@<host ip>`
---


# Git

- [https://product.hubspot.com/blog/git-and-github-tutorial-for-beginners](https://product.hubspot.com/blog/git-and-github-tutorial-for-beginners)
- [https://docs.gitlab.com/ee/gitlab-basics/start-using-git.html](https://docs.gitlab.com/ee/gitlab-basics/start-using-git.html)

## Configure Git
1) Check configuration of Git on local PC: `git config --global --list`
2) Change your local credentials (username): `git config --global user.name "yourname"`
3) Change your local credentials (email): `git congif --global user.email "youremail"`


## Initialize
1) Launch Git Bash
2) Navigate to project directory
3) initialize git repository in the folder root: `git init`
4) create new file in directory: `touch filename.extension`
5) list files in root: `ls`
6) check which files git recognizes: `git status`


## Staging
A commit is a record of what files you have changed since the last time you made a commit. 
Essentially, you make changes to your repo (for example, adding a file or modifying one) 
and then tell git to put those files into a commit.
Commits make up the essence of your project and allow you to go back to the state of a project at any point.

So, how do you tell git which files to put into a commit? 
This is where the staging environment or index come in. 
When you make changes to your repo, git notices that a file has changed but 
won't do anything with it (like adding it in a commit).

To add a file to a commit, you first need to add it to the staging environment. 
To do this, you can use the `git add <filename>` command.

Once you've used the git add command to add all the files you want to the staging environment, 
you can then tell git to package them into a commit using the git commit command. 
Note: The staging environment, also called 'staging', is the new preferred term for this, 
but you can also see it referred to as the 'index'.

1) Add files to the staging environment: `git add filename.extension`
2) Check staging environment for new files: `git status`


## Commit Locally
`git commit -m "Your message about the commit"`


## Branches
Say you want to make a new feature but are worried about making changes to the main project 
while developing the feature. This is where git branches come in. 

Branches allow you to move back and forth between 'states' of a project. 
For instance, if you want to add a new page to your website you can create a new branch just 
for that page without affecting the main part of the project. Once you're done with the page, 
you can merge your changes from your branch into the master branch. 
When you create a new branch, Git keeps track of which commit your branch 'branched' off of, 
so it knows the history behind all the files. 

1) `git checkout -b <my branch name>`
2) Show list of branches: `git branch`


## Commit to Github
1) Create new repo on GitHub
2) `git remote add origin <url produced on github for new repo>`
3) `git push -u origin [master/main]`


## Push a Branch to Github
`git push origin <my-new-branch>`

You might be wondering what that "origin" word means in the command above. 
What happens is that when you clone a remote repository to your local machine, git creates an alias for you. 
In nearly all cases this alias is called "origin." It's essentially shorthand for the remote repository's URL. 
So, to push your changes to the remote repository, 
you could've used either the command: git push git@github.com:git/git.git yourbranchname or git push origin yourbranchname


## Pull Request
A pull request (or PR) is a way to alert a repo's owners that you want to make some changes to their code. 
It allows them to review the code and make sure it looks good before putting your changes on the master branch.


## Get Changes on Github
`git pull origin master`

check all new commits: `git log`


## View Differences
1) run: `git diff`


## Remove a Branch
### Locally
`git branch -d <branch_name>`

### Remote
`git push <remote_name> --delete <branch_name>`

## Remove tracked file/directory
### File
`git rm --cached <file>`

### Directory
`git rm --cahced -r dir/`


---


# Database Commands

## psql
[Cheat sheet](https://quickref.me/postgres)
```{r psql, echo=F}
t4 <- read_excel(f, sheet="psql-commands")
# Show all rows in table (no pagination)
datatable(t4, options=list(paging=FALSE), rownames=F)
```


### Export table to CSV
- `\copy table TO '<path>' CSV`
- `\copy table(col1,col1) TO '<path>' CSV`
- `\copy (SELECT...) TO '<path>' CSV`


### Backup
Use pg_dumpall to backup all databases

`$ pg_dumpall -U postgres > all.sql`

Use pg_dump to backup a database

`$ pg_dump -d mydb -f mydb_backup.sql`

- &nbsp; `-a` &nbsp; Dump only the data, not the schema
- &nbsp; `-s` &nbsp; Dump only the schema, no data
- &nbsp; `-c` &nbsp; Drop database before recreating
- &nbsp; `-C` &nbsp; Create database before restoring
- &nbsp; `-t` &nbsp; Dump the named table(s) only
- &nbsp; `-F` &nbsp; Format (`c`: custom, `d`: directory, `t`: tar)

Use `pg_dump -?` to get the full list of options


### Restore

#### psql

`$ psql -U user mydb < mydb_backup.sql`

#### pg_restore

`$ pg_restore -d mydb mydb_backup.sql -c`

- `-U   Specify a database user`
- `-c   Drop database before recreating`
- `-C   Create database before restoring`
- `-e   Exit if an error has encountered`
- `-F   Format (c: custom, d: directory, t: tar, p: plain text sql(default))`

Use pg_restore -? to get the full list of options