---
title: Data Quality
embed-resources: true
order: 2
---

Good decisions require high-quality data--and analytics, and engineering, and other disciplines, but data is the foundation of most decision support services.  The data we use is typically generated by processes that provide a broad scope for errors resulting from faulty recording, transcription, encoding, tabulation, presentation, and documentation.  Poor data quality may also result from omissions: sampling depths or depth units weren't recorded because of course everybody knows what they are; coordinates are not included in the data table because they're in a GIS file (that we did not get); report tables omit information so that they fit on the page better. Data preparation and presentation may also introduce data quality issues, such as when information is represented only by colors, font changes, footnotes, or other annotations.  Data don't fall from the sky in pure and perfect form, and so an important--and necessary--part of our work is to ensure that decisions and other deliverables are founded on high-quality data.

## Data Quality Dimensions

The term "data quality" is so all-encompassing that it can be hard to grasp or measure, with the result that it can be hard to determine or describe the level of data quality for a data set.  To make it more tractable, data quality can be described in terms of several specific sets of attributes.  These sets of attributes are called "data quality dimensions".  Various authors writing on data quality have defined data quality dimensions differently, but the dimensions of data quality that are most relevant to environmental data are:

- Data integrity
- Unambiguity
- Consistency
- Completeness
- Correctness
- Documentation

Each of these is a scalar quantity--i.e., can range from low to high, or bad to good--and although ideally every data set is at the top of the scale on all of these dimensions, this is rarely the case in practice.  Compromises often must be made, and ideally those are informed and deliberate compromises.  In most cases improvements in data quality can be made along any of the dimensions listed above.  If a data quality assessment is not performed, data uses may be compromised by data quality issues of unknown type and severity.

Consideration of these specific dimensions is useful when trying to identify and describe data quality issues.  These dimenstions are not completely distinct however.  For example, the overarching goal of establishing semantic consistency within the database relates to the dimensions of data integrity, unambiguity, and consistency.

Data quality assessments of new data sets is guided by the data entry and loading checklist. An initial evaluation is typically performed by visual examination, by filtering the data set in various ways if it is in a spreadsheet, or by importing it into a staging table (or tables) in a database and running queries to identify possible issues.  When compiling multiple data sets into a single database, data quality assessments must consider both each data set individually and issues related to its compatibility with other data sets. The quality of geographic coordinate data is assessed by check plots: mapping the given coordinates with one or several different assumptions about the applicable spatial reference system, and then comparing the result to location descriptions, to physical features (such as river or shoreline boundaries), and to any maps available from the original data source.  If the data are to be loaded into any database with properly designed relational constraints, during the loading process the database itself may identify additional data quality issues that are not easily perceived by simple interactive review of the data.

Depending on the number and type of data integrity issues, the data manager may record these in an issue log to document both the nature of each issue and its ultimate resolution.  Use of issue logs may be required, if specified in the project plan or data management plan for a project, or may otherwise be created at the discretion of the data manager.

## Data Integrity

### What data integrity means

Data integrity means that different types of information are properly identified and related to one another.  There are three elements of data integrity:

- **Uniqueness**.  For example, each field sample that is collected must be uniquely identified.
- **Relational integrity**. For example, each analytical result must be related to (the measurement made on) a single sample.
- **Domain integrity**.  For example, a concentration should be numeric, not a combination of a number and some qualifier or other annotation.  Also, coded values such as analytes and units must be within the set of valid values.

Data integrity problems are extremely common in data sets that data managers receive from third parties, particularly when a large data set is provided in the form of a single table. Data integrity problems also arise from hand-entry of field sampling information, even in work conducted by technical staff.

### How we establish or improve data integrity

The best way to establish and maintain data integrity is to define and enforce appropriate rules for uniqueness and relational integrity.  A properly designed relational database includes those rules and automatically enforces them.  Establishment of data integrity is one of the advantages of using a relational database, and is the primary tool used by data mangement staff to guarantee data integrity.

Migration of a data set that is lacking data integrity into a database that enforces data integrity requires that the integrity issues be addressed.  This may be done by:

- Acquiring additional information to resolve the problems.  This information may come from work plans, field forms, reports, or interviews with individuals responsible for data collection or preparation.
- Making and documenting assumptions about which data sources or data items are most reliable.  For example, if there are multiple collection dates for the same sample identifier, either the identifier or the recorded date may be assumed to be the correct value.  Such assumptions may be based on overall characteristics of the data set such as the rules used to construct sample identifiers or the consistency of a sequence of sampling dates.
- Making and documenting decisions about acceptable compromises to data quality.  For example if there are multiple collection dates recorded for a sample, if date is not important to data use, then a decision may be made to use either the first or last recorded date; if date is important, then more effort will need to be expended to resolve the issue.

## Unambiguity

### What unambiguity means

There are several types of ambiguity that are frequently found in data sets:

- **Column names**. Is a column named `Sample type` meant to distinguish between sediment, water, and tissue samples; between natural and field QC samples; between site and background samples; between original and confirmation samples, or something else?
- **Coordinates**. Geographic coordinates that are not accompanied by a spatial reference system identifier (i.e., a datum and possibly a projection) are ambiguous.  For examples, coordinates in decimal degrees may be based on either a NAD83 or WGS84 datum (or possibly others), and the difference may amount to a perceptible and important difference in where locations are shown on maps.
- **Dates and times**. Does `5/8/2016` mean `May 8` or `August 5`?  Does a time of `7:32` represent `AM` or `PM`? What time zone is that in?
- **Codes**. Units of `%` can be ambiguous if it is not known whether this is a mass percent or volume percent; this ambiguity can prevent conversion of units.  In field records containing fish species codes, species codes such as `FP` can be ambiguous if not accompanied by an unambiguous taxon name.  In analytical chemistry results that include analytes named `PAH` and `Total PAH`, these can be ambiguous if it is not clear whether or not they are meant to be the same thing.

Ambiguity of coordinates and codes is very common, and often not easily resolved by inspection of the data or by reasonable assumptions.

### How we reduce data ambiguity

The approach used to resolve an ambiguity vary depending on the nature of that ambiguity, but may include:

- Searching for clarifying information in work plans, final reports, and other related documentation.
- Factoring codes into two or more distinct sets of unambiguous valid values.
- Applying default assumptions (e.g., for date formats).
- Using unambiguous column names.

## Consistency

### What consistency means

Consistency means that the same type of information is always represented in the same way.  Consistency issues almost always arise when integrating data from different sources.  Valid value lists ordinarily differ between different data sources, but inconsistency in the use of valid values is often also found within individual data sets.  Consistency issues often underlie issues of ambiguity and completeness.  Data sets may differ in the consistency of data structure and reporting detail; for example, one data set may include analytical data down to the individual laboratory replicate, whereas another may contain only data summarized to the level of the interpretive sample; one data set may contain a detailed description of the type of material collected and analyzed, whereas another may contain only the laboratory's characterization of the material (so that sediment is identified as soil, for example).

### How we establish or improve data consistency

Resolving each data consistency issue is ordinarily carried out by data-set-specific code in the SQL scripts that are used to load the data.  Consistency of valid values is established by using translation tables that convert codes in source data sets to the valid values.

## Completeness

### What completeness means

There are two aspects to data completeness:

1. We have all of the relevant data sets
1. No required data are missing from any of the data sets.

Whether an individual data set is complete therefore depends on what data are required, which may be project-specific.  The database should impose a minimum set of requirements necessary to ensure data integrity.  Any additional requirements should be specified in the project plan, Data Management Plan, Data Manager's Manual, or in the project initiation checklist.

### How we establish or improve data completeness

Determination of whether or not we have all of the data is sometimes simple: we collected the data ourselves, or the client sent us the data and assured us that all of the data have been provided (this is not always true, of course).  In other circumstances we may need to spend substantial effort to identify and collect all of the data relevant to a particular project.  To support such efforts, we have a template for a data set inventory (database) and procedures for populating the inventory, prioritizing its contents, and tracking data loading efforts.

The ideal method to resolve completeness issues for an individual data set is to obtain the missing information from accessory sources of information such as work plans, field sampling plans, field logbooks and notes, laboratory data packages, and data reports.  When this approach is insufficient because the documents are unavailable or are themselves incomplete, a fallback approach, to be used when necessary and appropriate, is to use default or synthesized values.  Examples of this approach are:

- When dates are provided only to the month, but dates are required to be specified to the day, the first day of the month is assigned.
- When location identifiers are missing, they are synthesized from the sample identifiers or other available information as appropriate.
- When environmental sample identifiers are missing, they may be synthesized by concatenating location identifiers, dates, and depths.
- When laboratory sample identifiers are missing, the environmental sample identifiers are used.
- When laboratory replicate identifiers are missing, default values of "1", "2", etc., are assigned.

## Correctness

### What correctness means

Correctness for environmental data means that measurement results accurately represent environmental conditions at the location, date, and depth indicated.  In general this means that the data retain fidelity to the original data source after all of the translations and transformations that are carried to to standardize the data and resolve other data quality issues.  Deviations from the original data source may legitimately result from corrections or clarifications that result from resolving data quality issues.

### How we establish or improve data correctness

The two primary methods of assessing and improving data correctness are:

1. Established quality management program, specifically QA checks of data loading scripts and data compilations
2. Data validation for analytical chemistry data.

Some data correctness issues are only identified during data analyses.  For example, statistical analyses may flag certain data points as outliers, and further investigation may reveal that those values are the result of transcription or other errors, often originating in the primary data source.  Correctness is a data quality issue that should be attended to throughout all data uses within a project.

## Documentation

There are three types of documentation that are important with regard to data quality:

- **Provenance**: where the data came from.
- **Source documentation**: work plans, data reports, and other documentation that accompanied the data themselves
- **Documentation**: project plans, data management plans, completed checklists, issue logs, data manager's manuals, script header notes, automatically-generated execsql logs, custom script logs, and QA forms.

Study descriptions, location definitions, sample descriptions, and analytical chemical results (and other things) all must be linked to a source document citation.  Not all of the source documents may be used for this purpose, but all of the available documentation, of all types, can be added to the database to maintain a centralized record of all data-related documents.  A DocMgr system may also be set up for any project, and may include data-related documents as well as others.

Documentation of a data set's provenance is often missing. The origin of a data set may be known to some project staff, but not others.  This can be a limitation when questions or issues need to be communicated back to the data provider, or when issues are identified and the PIC asks "Where did these data come from?".  The recommended approach to documenting a data set's provenance is to create a file containing that information in the same directory (ordinarily under the project's Data directory) in which the data files themselves are saved.  If the data were received by email, printing the email to a PDF file is recommended; otherwise, the information should be documented in a text or Word file.

## Application Specifics

The table at the link below identifies specific considerations for each of the data quality dimensions, for several different stages of the data lifecycle.

{{<
downloadthis
../../static/data-management/applications-of-data-quality-dimensions.xlsx
dname="applications-of-data-quality-dimensions"
label="applications-of-data-quality-dimensions.xlsx"
type=primary
>}}

## Summary

Data quality is important and multifaceted.  The DMA practice has established standards and procedures to address all the dimensions of data quality that are within their purview.  An understanding of how to assess data quality and address data quality issues is also a component of data literacy.

## Federal and State Guidance on Data Quality

The following table is a compilation of federal and state guidance documents that pertain to data quality.  These almost all pertain specifically to chemistry data quality, rather than data quality in general.

Authority | Government Organization | Reference / Link
--- | --- | ---
Federal | US Department of Defense (DoD) | [Uniform Federal Policy (UFP) for Quality Assurance Project Plans (QAPPs)](http://ttps/www.epa.gov/fedfac/uniform-federal-policy-quality-assurance-project-plans-training-materials)
Federal | US Department of the Navy (DoN) | [DON Sampling and Analysis Plan (SAP)](https://www.navfac.navy.mil/navfac_worldwide/specialty_centers/exwc/products_and_services/ev/go_erb/program-support/systematic-planning.html)
Federal | US Environmental Protection Agency (USEPA) | [How EPA Manages the Quality of its Environmental Information - US EPA](https://www.epa.gov/quality)
Federal | US Environmental Protection Agency (USEPA) | [Guidance for Quality Assurance Project Plans, EPA QA/G-5 - US EPA](https://www.epa.gov/quality/guidance-quality-assurance-project-plans-epa-qag-5)
Federal | US Environmental Protection Agency (USEPA) | [Guidance on Systematic Planning Using the Data Quality Objectives Process, EPA QA/G-4 - US EPA](https://www.epa.gov/quality/guidance-systematic-planning-using-data-quality-objectives-process-epa-qag-4)
Federal | US Environmental Protection Agency (USEPA) | [Agency-wide Quality Program Documents - US EPA](https://www.epa.gov/quality/agency-wide-quality-program-documents)
Regional EPA  Guidance | US EPA Region 1 | [Managing the Quality of Environmental Data at EPA Region 1 - US EPA](https://www.epa.gov/quality/managing-quality-environmental-data-epa-region-1)
Regional EPA  Guidance | US EPA Region 2 | [US EPA Region 2 Guidance for the Development of Quality Assurance Project Plans for Environmental Monitoring Projects - US EPA](https://www.epa.gov/quality/us-epa-region-2-guidance-development-quality-assurance-project-plans-environmental)
Regional EPA  Guidance | US EPA Region 3 | [EPA Region 3 Quality Assurance Project Plans - US EPA](https://www.epa.gov/quality/epa-region-3-quality-assurance-project-plans)
Regional EPA  Guidance | US EPA Region 4 | [Region 4 Quality Assurance Project Plan (QAPP) Tool Box - US EPA](https://www.epa.gov/brownfields/region-4-quality-assurance-project-plan-qapp-tool-box)
Regional EPA  Guidance | US EPA Region 5 | [Managing the Quality of Environmental Data at EPA Region 5 - US EPA](https://www.epa.gov/quality/managing-quality-environmental-data-epa-region-5)
Regional EPA  Guidance | US EPA Region 6 | [Managing the Quality of Environmental Data at EPA Region 6 - US EPA](https://www.epa.gov/quality/managing-quality-environmental-data-epa-region-6)
Regional EPA  Guidance | US EPA Region 7 | [Managing the Quality of Environmental Data at EPA Region 7 - US EPA](https://www.epa.gov/quality/managing-quality-environmental-data-epa-region-7)
Regional EPA  Guidance | US EPA Region 8 | [Managing the Quality of Environmental Data at EPA Region 8 - US EPA](https://www.epa.gov/quality/managing-quality-environmental-data-epa-region-8)
Regional EPA  Guidance | US EPA Region 9 | [Region 9 Wetlands Quality Assurance Project Plan Guidance and Template - US EPA](https://www.epa.gov/quality/region-9-wetlands-quality-assurance-project-plan-guidance-and-template)
Regional EPA  Guidance | US EPA Region 10 | [Quality Assurance Project Plans for Tribes in Region 10 - US EPA](https://www.epa.gov/r10-tribal/quality-assurance-project-plans-tribes-region-10)
State Guidance | Alaska (ADEC) | [Division of Water Quality Assurance](https://dec.alaska.gov/water/water-quality/quality-assurance/)<br>[Division of Air Quality Monitoring and Quality Assurance](https://dec.alaska.gov/air/air-monitoring/quality-assurance-plans/)
State Guidance | Connecticut (DEEP) | [Quality Assurance (ct.gov)](https://portal.ct.gov/DEEP/About/Quality-Assurance)
State Guidance | Illinois (IEPA) | [Guidance - Resource Assessments (illinois.gov)](https://www2.illinois.gov/epa/topics/water-quality/watershed-management/resource-assessments/Pages/guidance.aspx)
State Guidance | Indiana (IDEM) | [IDEM: Nonpoint Source: Quality Assurance Project Plan Template Instructions](https://www.in.gov/idem/nps/quality-assurance-project-plan-template-instructions/)
State Guidance | Massachusetts (DEP) | [https://www.mass.gov/lists/quality-assurance-project-plans](https://www.mass.gov/lists/quality-assurance-project-plans)
State Guidance | Minnesota (MPCA) | [MPCA Quality Assurance Project Plan Guidance (p-aeo2-13)](https://www.pca.state.mn.us/sites/default/files/p-eao2-13.pdf)<br>[Underground Storage Tank and Petroleum Remediation Quality Assurance Program Plan (p-eao2-04)](https://www.pca.state.mn.us/sites/default/files/p-eao2-04.pdf)<br>[Toxic Substances Control Act Polychlorinated Biphenyl Inspection Program QAPP (p-eao2-08)](https://www.pca.state.mn.us/sites/default/files/p-eao2-08.pdf)
State Guidance | Missouri (DNR) | Missouri Department of Natural Resources Data Quality Management Brownfields Quality Assurance Project Plan Templates<br>[Data Quality Management - Missouri Department of Natural Resources (mo.gov)](https://dnr.mo.gov/waste-recycling/business-industry/guidance-technical-assistance/data-quality-management)
State Guidance | New Jersey (DEP) | [Quality Assurance Project Plan Technical Guidance](https://www.nj.gov/dep/srp/guidance/srra/quality_assurrance_project_plan_guidance.pdf)
State Guidance | New York State (NYSDEC) | [Quality Assurance and Quality Control of Water Quality Data](https://www.dec.ny.gov/chemical/23850.html)
State Guidance | South Carolina (DHEC) | [Guidance Document for Preparing Quality Assurance Project Plans (QAPPs) for Environmental Monitoring Projects/Studies](https://scdhec.gov/quality-assurance-plans)<br>[Underground Storage Tank (UST) Quality Assurance Program Plan (QAPP)](https://scdhec.gov/environment/land-waste/underground-storage-tanks/release-assessment-clean/quality-assurance)
State Guidance | Texas (TCEQ) | [Quality Assurance Project Plans for Nonpoint Source Projects](https://www.tceq.texas.gov/waterquality/nonpoint-source/nps-qapp)<br>[Quality Assurance and Monitoring Procedures for Surface Water Quality Monitoring](https://www.tceq.texas.gov/waterquality/monitoring/swqm_guides.html)<br>[Air Quality Research: Quality Assurance](https://www.tceq.texas.gov/airquality/airmod/project/quality-assurance)<br>[Texas Risk Reduction Program](https://www.tceq.texas.gov/remediation/trrp/trrp.html)
State Guidance | Washington State (Ecology) | [Guidelines for Preparing Quality Assurance Project Plans for Environmental Studies](https://apps.ecology.wa.gov/publications/documents/0403030.pdf)<br>[Washington State Department of Ecology Quality Management Plan 2020](https://apps.ecology.wa.gov/publications/documents/2003014.pdf)
