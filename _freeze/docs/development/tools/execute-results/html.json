{
  "hash": "ff7978ad81034dbf73b0cff4b4c1262c",
  "result": {
    "markdown": "---\ntitle: Tools\npagetitle: Tools\ndescription: Development Tools\nimage: /static/dev-tools.jpg\nformat:\n  html:\n    code-fold: true\nexecute:\n  echo: false\n---\n\n\n\n## Utility Functions\n\n### Movie \\> Gif\n\n`ffmpeg -i file.mov -s 600x400 -pix_fmt rgb24 -r 20 -f gif - | gifsicle --optimize=3 --delay=3 > file.gif`\n\n## Docker\n\n### Resources\n\n- [CheatSheet](../../static/development/Docker-CheatSheet.pdf)\n- [Convert Docker command to docker-compose.yml](https://www.composerize.com/)\n\n### Image vs. Container\n\n**Image** - Application we want to run\n\n**Container** - Instance of that image running as a process\n\n------------------------------------------------------------------------\n\n### Docker Basics\n\n#### Create an Nginx container\n\n`docker run -p 80:80 -d --name webhost nginx`\n\n1. Downloads Nginx from Docker Hub\n2. Starts new container from that image\n3. Opened port 80 on host IP\n4. Routes port 80 traffic to the container IP, port 80\n5. View container at <http://localhost:80>\n\n#### Other examples\n\n`docker run -p 80:80 -d --name nginx nginx`\n\n`docker run -p 8080:80 -d --name httpd httpd`\n\n`docker run -p 3306:3306 --platform linux/amd64 -d --name mysql -e MYSQL_RANDOM_ROOT_PASSWORD=true mysql`\n\nCreate a JupyterLab instance and attach your current directory as a volume: `docker run -it --rm -p 8888:8888 -v $(PWD):/home/jovyan jupyter/pyspark-notebook`\n\n#### Processes and configurations\n\nCheck processes running inside a container: `docker top <container>`\n\nContainer configuration: `docker <container> inspect`\n\nCheck container stats (memory, cpu, network): `docker stats <container>`\n\n#### Getting a shell inside containers\n\nStart a new container interactively: `docker run -it <container>`\n\nRun commands in existing container: `docker exec -it <container>`\n\n##### Example: Start a container interactively and launch bash within it\n\n1. Start container and launch bash: `docker run -it --name ubuntu ubuntu bash`\n2. Run some bash command: `apt-get install -y curl`\n3. Exit the container: `exit`\n4. Start and re-enter the container: `docker start -ai ubuntu`\n\n##### Example: Launch shell in running container\n\n`docker exec -it <container> bash`\n\n#### Pull an image from docker hub\n\n`docker pull <imagename>`\n\n### Docker Networks\n\n- Each container is connected to a private virtual network (called \"bridge\").\n- Each virtual network routes through NAT firewall on host IP.\n- All containers on a virtual network can talk to each other without `-p`\n- ***Best practice***: Create a new virtual network for each app.\n- You can skip virtual networks and use the host IP (`--net=host`).\n\nGet container IP: `docker inspect --format '{{ .NetworkSettings.IPAddress }}' <container>`\n\n#### Publishing (#:#)\n\nexample: 8080:80\n\n**left number**: published/host port\n\n**right number**: listening/container port\n\n*Traffic passing through port 8080 on the HOST will be directed to port 80 on the container.*\n\n#### DNS\n\nDocker uses container names as host names.\n\nDont rely on IPs for inter-communication.\n\n***Best Practice*** Always use custom networks.\n\n##### Assignment\n\nCheck different curl versions within current versions of Ubuntu and CentOS.\n\nRun \"curl --version\" on both operating systems.\n\n###### Steps\n\n**ubuntu**: `apt-get update && apt-get install curl`\n\n**centos**: `yum update curl`\n\nThen...\n\n`curl --version`\n\nAlso:\n\nCheck out command `docker --rm`\n\n### Dockerfiles\n\nRecipe for creating images\n\nEach Dockerfile stanza such as \"RUN\", \"CMD\", etc. are stored as a single image layer. Docker caches each layer by giving it a unique SHA (hash), so whenever the image is (re)built, it can check to see if a layer has changed, and if not, it will use the cached layer.\n\nDocker builds images top down, so it is best practice to structure the Dockerfile in such a way that lines which will change the most are at the bottom, and lines that will change the least are at the top. If a line is changed (ie. source code changes) Docker will rebuild that line, and thus each line after that will also need to be rebuilt.\n\n### Keeping the Docker system clean\n\n`docker system prune` - all stopped containers - all networks not used by at least one container - all dangling images - all dangling build cache\n\n### Volumes an Bind Mounts\n\n**Volumes** - Special location outside of container UFS\n\n**Bind Mounts** - Link container path to host path\n\nBuild an image and ***named*** volume (persistent): `docker run -d --name mysql -e MYSQL_ALLOW_EMPTY_PASSWORD=True -v mysql:/var/lib/mysql --platform linux/amd64 mysql`\n\n## Git\n\n- <https://product.hubspot.com/blog/git-and-github-tutorial-for-beginners>\n- <https://docs.gitlab.com/ee/gitlab-basics/start-using-git.html>\n\n### Initialize\n\n1. Launch Git Bash\n2. Navigate to project directory\n3. initialize git repository in the folder root: `git init`\n4. create new file in directory: `touch filename.extension`\n5. list files in root: `ls`\n6. check which files git recognizes: `git status`\n\n### Staging\n\nA commit is a record of what files you have changed since the last time you made a commit. Essentially, you make changes to your repo (for example, adding a file or modifying one) and then tell git to put those files into a commit. Commits make up the essence of your project and allow you to go back to the state of a project at any point.\n\nSo, how do you tell git which files to put into a commit? This is where the staging environment or index come in. When you make changes to your repo, git notices that a file has changed but won't do anything with it (like adding it in a commit).\n\nTo add a file to a commit, you first need to add it to the staging environment. To do this, you can use the `git add <filename>` command.\n\nOnce you've used the git add command to add all the files you want to the staging environment, you can then tell git to package them into a commit using the git commit command. Note: The staging environment, also called 'staging', is the new preferred term for this, but you can also see it referred to as the 'index'.\n\n1. Add files to the staging environment: `git add filename.extension`\n2. Check staging environment for new files: `git status`\n\n### Commit Locally\n\n`git commit -m \"Your message about the commit\"`\n\n### Branches\n\nSay you want to make a new feature but are worried about making changes to the main project while developing the feature. This is where git branches come in.\n\nBranches allow you to move back and forth between 'states' of a project. For instance, if you want to add a new page to your website you can create a new branch just for that page without affecting the main part of the project. Once you're done with the page, you can merge your changes from your branch into the master branch. When you create a new branch, Git keeps track of which commit your branch 'branched' off of, so it knows the history behind all the files.\n\n1. `git checkout -b <my branch name>`\n2. Show list of branches: `git branch`\n\n### Commit to Github\n\n1. Create new repo on GitHub\n2. `git remote add origin <url produced on github for new repo>`\n3. `git push -u origin [master/main]`\n\n### Push a Branch to Github\n\n`git push origin <my-new-branch>`\n\nYou might be wondering what that \"origin\" word means in the command above. What happens is that when you clone a remote repository to your local machine, git creates an alias for you. In nearly all cases this alias is called \"origin.\" It's essentially shorthand for the remote repository's URL. So, to push your changes to the remote repository, you could've used either the command: git push git\\@github.com:git/git.git yourbranchname or git push origin yourbranchname\n\n### Pull Request\n\nA pull request (or PR) is a way to alert a repo's owners that you want to make some changes to their code. It allows them to review the code and make sure it looks good before putting your changes on the master branch.\n\n### Get Changes on Github\n\n`git pull origin master`\n\ncheck all new commits: `git log`\n\n### View Differences\n\n1. run: `git diff`\n\n### Remove a Branch\n\n#### Locally\n\n`git branch -d <branch_name>`\n\n#### Remote\n\n`git push <remote_name> --delete <branch_name>`\n\n### Remove tracked file/directory\n\n#### File\n\n`git rm --cached <file>`\n\n#### Directory\n\n`git rm --cahced -r dir/`\n\n### pre-commit\n\nPlease make sure to install our [pre-commit](https://pre-commit.com/) hooks into your Git workflow. Pre-commit will help keep our code clean and make sure we are following best practices.\n\n- Install pre-commit hooks: `python -m pre_commit install --install-hooks`\n- Run hooks on the entire codebase: `python -m pre_commit run --all-files`\n\nHooks will run on the current commit snapshot when executing a `git commit`. Pre-commit hooks allow us to check for potential issues and make sure we are applying standards to our code before pushing to GitHub.\n\nSee an example [.pre-commit-config.yml](https://github.com/geocoug/python-app-template/blob/main/.pre-commit-config.yaml)\n\n### Merge\n\nThe steps below can be used to merge two branches on your local machine. The braches used in this example are:\n\n- `main`: The authoritative or \"production\" code lives in this branch.\n- `dev`: This branch is split from the `main` branch and a new feature or update is coded with the intent to merge changes back into the `main` branch.\n\n1. Pull `main` and `dev` branches so local repo is up to date with the remote.\n    1. `git checkout main`\n    1. `git pull origin main`\n    1. `git checkout dev`\n    1. `git pull origin dev`\n\n2. Checkout the main branch so we can merge the `dev` branch into `main`\n    1. `git checkout main`\n    1. `git merge dev`\n\n    ![git-merge](../../static/development/git-merge.png)\n\n3. Check the branch status: `git status`\n\n    ![git-status](../../static/development/git-status.png)\n\n4. Evaluate the two files with a conflict (ie. `.gitignore` and `requirements.txt`) and reconcile issues, then `git add` when ready.\n\n5. Commit the changes: `git commit -m \"merge @tnelson-integral dev branch with main\"`\n\n6. Push changes to the remote on GitHub: `git push origin main`\n\n7. Check out the `dev` branch locally and pull the `main` branch changes into it so `dev` can be up-to-date with `main`\n    1. `git checkout dev`\n    1. `git pull origin main`\n    1. `git push origin dev`\n\n## psql\n\n[Cheat sheet](https://quickref.me/postgres)\n\n::: {.cell execution_count=2}\n\n::: {.cell-output .cell-output-display execution_count=2}\n<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th>Command</th>\\n      <th>Detail</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <td>sudo -s postgres psql</td>\\n      <td>Connect to PostgreSQL as admin</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\l</td>\\n      <td>List all databases</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\c postgres</td>\\n      <td>Connect to the database named postgres</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\q</td>\\n      <td>Disconnect</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -d mydb</td>\\n      <td>Connecting to database</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -U john mydb</td>\\n      <td>Connecting as a specific user</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -h localhost -p 5432 mydb</td>\\n      <td>Connecting to a host/port</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -U admin -h 192.168.1.5 -p 2506 -d mydb</td>\\n      <td>Connect remote PostgreSQL</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -W mydb</td>\\n      <td>Force password</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -c \\'\\\\c postgres\\' -c \\'\\\\dt\\'</td>\\n      <td>Execute a SQL query or command</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -c \"\\\\l+\" -H postgres &gt; database.html</td>\\n      <td>Generate HTML report</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -l</td>\\n      <td>List all databases</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\dt</td>\\n      <td>Show all tables in a database</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# mydb -f file.sql</td>\\n      <td>Execute commands from a file</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -V</td>\\n      <td>Print the psql version</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\df &lt;schema&gt;</td>\\n      <td>List functions in schema</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\du</td>\\n      <td>Show current user permission</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\d &lt;table&gt;</td>\\n      <td>Describe table</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\d+ &lt;table&gt;</td>\\n      <td>Describe table with details</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\di</td>\\n      <td>List indexes</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\du</td>\\n      <td>List roles</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\ds</td>\\n      <td>List sequences</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\copy …</td>\\n      <td>Import/export table</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\echo [string]</td>\\n      <td>Print string</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\i [file]</td>\\n      <td>Execute file</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\o [file]</td>\\n      <td>Export all results to file</td>\\n    </tr>\\n  </tbody>\\n</table>\n:::\n:::\n\n\n### Export table to CSV\n\n- `\\copy table TO '<path>' CSV`\n- `\\copy table(col1,col1) TO '<path>' CSV`\n- `\\copy (SELECT...) TO '<path>' CSV`\n  \n### Backup\n\nUse pg_dumpall to backup all databases\n\n`$ pg_dumpall -U postgres > all.sql`\n\nUse pg_dump to backup a database\n\n`$ pg_dump -d mydb -f mydb_backup.sql`\n\n- `-a`   Dump only the data, not the schema\n- `-s`   Dump only the schema, no data\n- `-c`   Drop database before recreating\n- `-C`   Create database before restoring\n- `-t`   Dump the named table(s) only\n- `-F`   Format (`c`: custom, `d`: directory, `t`: tar)\n\nUse `pg_dump -?` to get the full list of options\n\n### Restore\n\n`$ psql -U user mydb < mydb_backup.sql`\n\n#### pg_restore\n\n`$ pg_restore -d mydb mydb_backup.sql -c`\n\n- `-U   Specify a database user`\n- `-c   Drop database before recreating`\n- `-C   Create database before restoring`\n- `-e   Exit if an error has encountered`\n- `-F   Format (c: custom, d: directory, t: tar, p: plain text sql(default))`\n\nUse pg_restore -? to get the full list of options\n\n",
    "supporting": [
      "tools_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}