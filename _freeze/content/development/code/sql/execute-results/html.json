{
  "hash": "31adaf4cf63f6ddb5476a6efe261c0a0",
  "result": {
    "markdown": "---\ntitle: SQL\ndescription: Structured Query Language\nimage: https://img.icons8.com/?size=512&id=MBA5vPE4dGz2&format=png\nfilters:\n    - interactive-sql\ndatabases:\n  - name: hr\n    # Must be served from a server\n    path: \"https://raw.githubusercontent.com/shafayetShafee/interactive-sql/main/hr.sql\"\n\n---\n\nThe code snippets on this page are primarily geared towards the PostgreSQL dialect.\n\n## Fundamentals\n\n### Primary Key Relationships\n\n**Columns**\n\n- table_schema: PK schema name\n- table_name: PK table name\n- constraint_name: PK constraint name\n- position: index of column in table (1, 2, ...). 2 or higher means key is composite (contains more than one column)\n- key_column: PK column name\n\n**Rows**\n\n- One row represents one primary key column\n- Scope of rows: columns of all PK constraints in a database\n- Ordered by table schema, table name, column position\n\n```sql\nselect * from (\n -- Main query. Returns all tables\n select kcu.table_schema,\n     kcu.table_name,\n     tco.constraint_name,\n     kcu.ordinal_position as position,\n     kcu.column_name as key_column\n from information_schema.table_constraints tco\n join information_schema.key_column_usage kcu \n   on kcu.constraint_name = tco.constraint_name\n   and kcu.constraint_schema = tco.constraint_schema\n   and kcu.constraint_name = tco.constraint_name\n where tco.constraint_type = 'PRIMARY KEY'\n order by kcu.table_schema,\n    kcu.table_name,\n    position\n) main\nwhere table_name = 'd_location'\n```\n\n### Foreign Key Relationships\n\n**Columns**\n\n- foreign_table: foreign table schema and name\n- rel: relationship symbol implicating direction\n- primary_table: primary (rerefenced) table schema and name\n- fk_columns: list of FK colum names, separated with \",\"\n- constraint_name: foreign key constraint name\n\n**Rows**\n\n- One row represents one foreign key.\n- If foreign key consists of multiple columns (composite key) it is still represented as one row.\n- Scope of rows: all foregin keys in a database.\n- Ordered by foreign table schema name and table name.\n\n### Ordering Tables by FK\n\n```sql\ndrop table if exists dependencies cascade;\ncreate temporary table dependencies as\nselect \n  tc.table_name as child,\n  tu.table_name as parent\nfrom \n  information_schema.table_constraints as tc\n  inner join information_schema.constraint_table_usage as tu\n    on tu.constraint_name = tc.constraint_name\nwhere \n  tc.constraint_type = 'FOREIGN KEY'\n  and tc.table_name <> tu.table_name;\n\nwith recursive dep_depth as (\nselect\n  dep.child, dep.parent, 1 as lvl\nfrom\n  dependencies as dep\nunion all\nselect\n  dep.child, dep.parent, dd.lvl + 1 as lvl\nfrom\n  dep_depth as dd\n  inner join dependencies as dep on dep.parent = dd.child\n)\nselect\n  table_name, table_order\nfrom (\n  select\n    dd.parent as table_name, max(lvl) as table_order\n  from\n    dep_depth as dd\n  group by\n    table_name\n  union\n  select\n    dd.child as table_name, max(lvl) + 1 as level\n  from\n    dep_depth as dd\n    left join dependencies as dp on dp.parent = dd.child\n  where\n    dp.parent is null\n  group by dd.child\n) as all_levels\norder by table_order;\n```\n\n### Return FK relationships for all tables\n\n```sql\nselect * from (\n -- Main query. Returns FK relationships for all tables\n select \n   kcu.table_schema as table_schema,\n   kcu.table_name as foreign_table,\n     '>-' as relationship,\n     rel_tco.table_name as primary_table,\n     string_agg(kcu.column_name, ', ') as fk_columns,\n     kcu.constraint_name\n from information_schema.table_constraints tco\n join information_schema.key_column_usage kcu\n     on tco.constraint_schema = kcu.constraint_schema\n     and tco.constraint_name = kcu.constraint_name\n join information_schema.referential_constraints rco\n     on tco.constraint_schema = rco.constraint_schema\n     and tco.constraint_name = rco.constraint_name\n join information_schema.table_constraints rel_tco\n     on rco.unique_constraint_schema = rel_tco.constraint_schema\n     and rco.unique_constraint_name = rel_tco.constraint_name\n where tco.constraint_type = 'FOREIGN KEY'\n group by kcu.table_schema,\n    kcu.table_name,\n    rel_tco.table_name,\n    rel_tco.table_schema,\n    kcu.constraint_name\n order by kcu.table_schema,\n    kcu.table_name\n) main\nwhere primary_table = 'd_location'\n```\n\n### Most Table Relationships\n\n[List tables with most relationships.](https://dataedo.com/kb/query/postgresql/list-tables-with-most-relationships)\n\n```sql\nselect * from\n(select relations.table_name as table_name, -- schema name and table name\n       count(relations.table_name) as relationships, -- number of table relationships\n       count(relations.referenced_tables) as foreign_keys, -- number of foreign keys in a table\n       count(relations.referencing_tables) as references, -- number of foreign keys that are refering to this table\n       count(distinct related_table) as related_tables, -- number of related tables\n       count(distinct relations.referenced_tables) as referenced_tables, -- number of different tables referenced with FKs (multiple FKs can refer to one table, so number of FKs might be different than number of referenced tables)\n       count(distinct relations.referencing_tables) as referencing_tables -- number of different tables that are refering to this table (similar to referenced_tables)\nfrom(\n     select pk_tco.table_schema || '.' || pk_tco.table_name as table_name,\n            fk_tco.table_schema || '.' || fk_tco.table_name as related_table,\n            fk_tco.table_name as referencing_tables,\n            null::varchar(100) as referenced_tables\n     from information_schema.referential_constraints rco\n     join information_schema.table_constraints fk_tco\n          on rco.constraint_name = fk_tco.constraint_name\n          and rco.constraint_schema = fk_tco.table_schema\n     join information_schema.table_constraints pk_tco\n          on rco.unique_constraint_name = pk_tco.constraint_name\n          and rco.unique_constraint_schema = pk_tco.table_schema\n    union all\n    select fk_tco.table_schema || '.' || fk_tco.table_name as table_name,\n           pk_tco.table_schema || '.' || pk_tco.table_name as related_table,\n           null as referencing_tables,\n           pk_tco.table_name as referenced_tables\n    from information_schema.referential_constraints rco\n    join information_schema.table_constraints fk_tco \n         on rco.constraint_name = fk_tco.constraint_name\n         and rco.constraint_schema = fk_tco.table_schema\n    join information_schema.table_constraints pk_tco\n         on rco.unique_constraint_name = pk_tco.constraint_name\n         and rco.unique_constraint_schema = pk_tco.table_schema\n) relations\ngroup by table_name\norder by relationships asc) results\n\nwhere substring(table_name, 5, 2) = 'd_'; -- substring(string, start_position, length)\n```\n\n### List column definitions and order between a set of tables\n\n```sql\nwith recursive\nmain_tables (\n    table_schema,\n    table_name\n) as (\nvalues\n    ('idb', 'd_document'),\n    ('idb', 'd_docfile'),\n    ('idb', 'd_study'),\n    ('idb', 'd_location'),\n    ('idb', 'd_studylocation'),\n    ('idb', 'd_sampcoll'),\n    ('idb', 'd_sampmain'),\n    ('idb', 'd_sampsplit'),\n    ('idb', 'd_labsample'),\n    ('idb', 'd_labpkg'),\n    ('idb', 'd_labresult')\n),\nexclude_columns (column_name) as (\n    values\n    ('gid'),\n    ('studyloc_alias'),\n    ('sampcoll_alias'),\n    ('sample_alias'),\n    ('analresult_alias'),\n    ('rev_user'),\n    ('rev_time')\n),\ndependencies as (\n    select\n        tc.table_name as child,\n        tu.table_name as parent\n    from\n        information_schema.table_constraints as tc\n        inner join information_schema.constraint_table_usage as tu\n            on tu.constraint_name = tc.constraint_name\n    where\n        tc.constraint_type = 'FOREIGN KEY'\n        and tc.table_name <> tu.table_name\n),\ndep_depth as (\n    select\n        dep.child, dep.parent, 1 as lvl\n    from\n        dependencies as dep\n    union all\n    select\n        dep.child, dep.parent, dd.lvl + 1 as lvl\n    from\n        dep_depth as dd\n        inner join dependencies as dep on dep.parent = dd.child\n    ),\ntable_order as (\n    select\n        all_levels.table_name, all_levels.table_order\n    from (\n        select\n            dd.parent as table_name, max(lvl) as table_order\n        from\n            dep_depth as dd\n        group by\n            table_name\n        union\n        select\n            dd.child as table_name, max(lvl) + 1 as level\n        from\n            dep_depth as dd\n            left join dependencies as dp on dp.parent = dd.child\n        where\n            dp.parent is null\n        group by dd.child\n    ) as all_levels\n    order by table_order\n),\ncols as (\n    select\n        cc.table_name,\n        -- Some column names need changing because they exist in multiple tables\n        case\n            when cc.column_name in ('comments', 'description', 'fraction')\n            then replace(cc.table_name, 'd_', '') || '_' || cc.column_name\n            else cc.column_name end as column_name,\n        data_type,\n        character_maximum_length,\n        is_nullable,\n        table_order,\n        ordinal_position,\n        row_number() over () as col_order\n    from\n        information_schema.columns as cc\n        inner join table_order on table_order.table_name=cc.table_name\n        inner join main_tables on \n            main_tables.table_schema=cc.table_schema \n            and main_tables.table_name=cc.table_name\n        left join exclude_columns on cc.column_name=exclude_columns.column_name\n    where exclude_columns.column_name is null\n    order by table_order.table_order, table_order.table_name, cc.ordinal_position\n)\nselect distinct\n    cols.column_name,\n    cols.column_name\n        || ' '\n        || data_type\n        || case\n                when character_maximum_length is null\n                then ''\n                else '(' || character_maximum_length || ')'\n                end\n     -- || case when not is_nullable::boolean then ' NOT NULL' else '' end as col_def,\n        as col_def,\n    cols.table_order, cols.table_name, cols.ordinal_position, row_number() over () as col_order\nfrom cols\norder by cols.table_order, cols.table_name, cols.ordinal_position\n```\n\n### Common Functions\n\n- `LENGTH(string)`: Returns the length of the provided string\n- `POSITION(string IN substring)`: Returns the position of the substring within the specified string.\n- `CAST(expression AS datatype)`: Converts an expression into the specified data type.\n- `NOW: Returns the current date, including time.\n- `CEIL(input_val)`: Returns the smallest integer greater than the provided number.\n- `FLOOR(input_val)`: Returns the largest integer less than the provided number.\n- `ROUND(input_val, [round_to])`: Rounds a number to a specified number of decimal places.\n- `TRUNC(input_value, num_decimals)`: Truncates a number to a number of decimals.\n- `REPLACE(whole_string, string_to_replace, replacement_string)`: Replaces one string inside the whole string with another string.\n- `SUBSTRING(string, [start_pos], [length])`: Returns part of a value, based on a position and length.\n\n### Add Role\n\n```sql\ncreate user <username> with password 'password'; -- <1>\ngrant connect on database <db_name> to <username>; -- <1>\ngrant usage on schema <schema_name> to <username>; -- <1>\ngrant select on all tables in schema <schema_name> to <username>; -- <1>\nalter default privileges in schema <schema_name> grant select on tables to <username>; -- <1>\n\ngrant create on database <db_name> to <username>; -- <2>\ngrant insert on database <db_name> to <username>; -- <3>\ngrant update on database <db_name> to <username>; -- <4>\ngrant update on database <db_name> to <username>; -- <5>\n```\n\n1. Create a read-only user.\n2. Allow user to create database objects.\n3. Allow user to insert rows to any schema and table.\n4. Allow user to update rows in any schema and table.\n5. Allow user to delete rows in any schema and table.\n\n### Create read only user - shorthand\n\nOnce already creating a specific user role, you can user the \\`pg\\_read\\_all_data\\` to grant read only access to all tables.\n\n```sql\nGRANT pg_read_all_data TO username;\n```\n\n### Finding Temporary Objects\n\n```sql\nSELECT\n n.nspname as SchemaName,\n c.relname as RelationName,\n CASE c.relkind\n  WHEN 'r' THEN 'table'\n  WHEN 'v' THEN 'view'\n  WHEN 'i' THEN 'index'\n  WHEN 'S' THEN 'sequence'\n  WHEN 's' THEN 'special'\n  END as RelationType,\n pg_catalog.pg_get_userbyid(c.relowner) as RelationOwner,             \n pg_size_pretty(pg_relation_size(n.nspname ||'.'|| c.relname)) as RelationSize\nFROM pg_catalog.pg_class c\nLEFT JOIN pg_catalog.pg_namespace AS n ON n.oid = c.relnamespace\n WHERE  c.relkind IN ('r','s') \n AND  (n.nspname !~ '^pg_toast' and nspname like 'pg_temp%')\nORDER BY pg_relation_size(n.nspname ||'.'|| c.relname) DESC;\n```\n\n## SQL\n\n### Terminate backends of a particular user (\"test\")\n\nThis query will kill every backend user \"test\" is connected to.\n\n```sql\nWITH pids AS (\n  SELECT pid\n  FROM pg_stat_activity\n  WHERE usename='test'\n)\n\nSELECT pg_terminate_backend(pid)\nFROM pids;\n```\n\n### Cancel every running SQL commands from a particular user (\"test\")\n\nThis query will cancel every running query issued by the particular user \"test\".\n\n```sql\nWITH pids AS ( \n  SELECT pid \n  FROM pg_stat_activity \n  WHERE username='test' \n) \nSELECT pg_cancel_backend(pid) \nFROM pids;\n```\n\n### List tables in database\n\n```sql\nSELECT table_schema, table_name \nFROM information_schema.tables \nORDER BY table_schema,table_name;\n```\n\n### List columns in table\n\n```sql\nSELECT column_name\nFROM   information_schema.columns\nWHERE  table_schema = 'schema'\nAND    table_name = 'table';\n```\n\n### Create a read-only user\n\n```sql\ngrant connect on database db_name to user;\ngrant usage on schema schema_name to user;\ngrant select on all tables in schema schema_name to user;\nalter default privileges in schema schema_name grant select on tables to user;\n```\n\n### Create DB\n\n```sql\ncreate database <new_db_name> owner <user_or_group> template <name_of_db_to_use_as_template>;\n-- show search_path;\nset search_path to <default_schema>,public;\ncreate extension if not exists postgis;\ncreate extension if not exists dblink;\n\n-- Database Creation\n-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ncreate database <new_db_name> owner <user_or_group> template <name_of_db_to_use_as_template>;\n-- show search_path;\nset search_path to idb, public;\n\ngrant connect, temporary on database <new_db_name> to public;\ngrant all on database <new_db_name> to <user>;\ngrant all on database <new_db_name> to <group>;\n\ncreate extension if not exists postgis;\ncreate extension if not exists dblink;\n\ncreate schema staging;\n\n-- Add a unique constraint to e_analyte.full_name and e_analyte.cas_rn so that\n-- no full name or cas_rn can be used for more than one analyte\n-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nalter table e_analyte\n  add constraint uc_fullname unique(full_name),\n  add constraint uc_casrn unique(cas_rn);\n```\n\n### DBLink\n\n```sql\nselect\n  a.*, b.*\nfrom\n  table1 as a\n  left join (\n    select * from dblink(\n      'dbname=<database>',\n      'select col1, col2, col3 from <table>'\n    ) as d (\n      col1 text, col2 text, col3 text\n    )\n  ) as b\n  on a.col1 = b.col2\n```\n\n### Partitioning\n\n```sql\nselect * from (\n    select *, row_number() over(\n        partition by\n            col1, col2, col3\n        order by col1 desc\n    ) rowid\n    from sometable\n) someid\nwhere rowid > 1;\n```\n\n### Current Database\n\n```sql\nselect * from pg_catalog.current_database()\n```\n\n### Current user/role\n\n```sql\nselect * from current_role\nselect * from current_user\n```\n\n### Process ID\n\n```sql\nselect * from pg_catalog.pg_backend_pid()\n```\n\n### List functions/defs/args\n\n```sql\nselect \n pg_get_userbyid(p.proowner) as owner,\n n.nspname as function_schema,\n p.proname as function_name,\n l.lanname as function_language,\n case when l.lanname = 'internal' then p.prosrc\n  else pg_get_functiondef(p.oid)\n  end as definition,\n pg_get_function_arguments(p.oid) as function_arguments,\n t.typname as return_type\nfrom pg_proc p\n left join pg_namespace n on p.pronamespace = n.oid\n left join pg_language l on p.prolang = l.oid\n left join pg_type t on t.oid = p.prorettype \nwhere n.nspname not in ('pg_catalog', 'information_schema')\nand n.nspname = 'idb'\norder by function_schema, function_name;\n```\n\n### Whos logged in\n\n```sql\nselect * from pg_stat_activity\nwhere usename != '' and usename != 'postgres'\norder by usename, pid\n```\n\n### Aggregate Functions\n\n[pg_aggregate catalog](https://www.postgresql.org/docs/9.6/catalog-pg-aggregate.html)\n\n```sql\n-- pg_proc contains data for aggregate functions as well as plain functions\nselect * from pg_proc\n-- pg_aggregate is an extension of pg_proc.\nselect * from pg_aggregate\n```\n\n### List users\n\n```sql\nSELECT rolname FROM pg_roles;\n```\n\n### Update From\n\n```sql\nUPDATE tablename\nSET columnname = someothervalue\nFROM ...\nWHERE ...\n```\n\n### Materialized View\n\n[Reference](https://www.postgresqltutorial.com/postgresql-materialized-views/)\n\n```sql\nCREATE MATERIALIZED VIEW view_name\nAS\nquery\nWITH [NO] DATA;\n```\n\nWhen you refresh data for a materialized view, PostgreSQL locks the entire table therefore you cannot query data against it. To avoid this, you can use the CONCURRENTLY option.\n\nWith CONCURRENTLY option, PostgreSQL creates a temporary updated version of the materialized view, compares two versions, and performs INSERT and UPDATE only the differences.\n\n```sql\nREFRESH MATERIALIZED VIEW CONCURRENTLY view_name;\n```\n\n### Constants\n\n```sql\nWITH myconstants (analyte_search) as (\n   values ('%Hexachlorocyclopentadiene%')\n)\n\nSELECT *\nFROM e_analyte, myconstants\nWHERE analyte ilike analyte_search\n   OR full_name ilike analyte_search\n   OR aliases ilike analyte_search;\n```\n\n### Sequential Keys\n\n```sql\nseq_key bigint NOT NULL DEFAULT nextval('seq_key'::regclass)\n\nALTER SEQUENCE seq_key RESTART WITH 3;\n```\n\n### Cross-Database Search\n\nThese could be refined further by creating a function.\n\n```sql\nwith\nconst (param) as (\n    values ('%solid%')\n),\ndbrows as (\n   select analyte, full_name, chem_class, aliases, cas_rn, current_database() as db from e_analyte\n  union\n    select * from dblink(\n        'dbname=database1',\n        'select analyte, full_name, chem_class, aliases, cas_rn, current_database() as db from e_analyte'\n        ) as d (analyte text, full_name text, chem_class text, aliases text, cas_rn text, db text)\n  union\n    select * from dblink(\n        'dbname=database2',\n        'select analyte, full_name, chem_class, aliases, cas_rn, current_database() as db from e_analyte'\n        ) as d (analyte text, full_name text, chem_class text, aliases text, cas_rn text, db text)\n  union\n    select * from dblink(\n     'dbname=database3',\n     'select analyte, full_name, chem_class, aliases, cas_rn, current_database() as db from e_analyte'\n ) as d (analyte text, full_name text, chem_class text, aliases text, cas_rn text, db text)\n)\nselect \n analyte, full_name, chem_class, cas_rn, aliases, \n count(*) as num_instances, string_agg(db, '; ') as db\nfrom dbrows, const\nwhere analyte ilike param\n   or full_name ilike param\n   or aliases ilike param\ngroup by analyte, full_name, chem_class, cas_rn, aliases\norder by chem_class, analyte;\n```\n\n### Logging\n\n#### Log slow queries by setting log\\_min\\_duration_statement\n\n```sql\nALTER database postgres SET log_min_duration_statement = '250ms';\n```\n\n#### Control which statement types get logged\n\nControl the types of statements that are logged for your database.\n\n```sql\nALTER DATABASE postgres SET log_statement = 'all';\n```\n\nValid values include all, ddl, none, mod\n\n#### Log when waiting on a lock\n\nLog when database is waiting on a lock.\n\n```sql\nALTER DATABASE postgres SET log_lock_waits = 'on';\n```\n\n### Performance\n\n#### Use statement timeouts to control runaway queries\n\nSetting a statement timeout prevents queries from running longer than the specified time. You can set a statement timeout on the database, user, or session level. We recommend you set a global timeout on Postgres and then override that one specific users or sessions that need a longer allowed time to run.\n\n```sql\nALTER DATABASE mydatabase SET statement_timeout = '60s';\n```\n\n#### Use pg\\_stat\\_statements to find the queries and processes that use the most resources\n\n```sql\nSELECT\n total_exec_time,\n mean_exec_time as avg_ms,\n calls,\n query\nFROM pg_stat_statements\nORDER BY mean_exec_time DESC\nLIMIT 10;\n```\n\n#### Monitor connections in Postgres\n\nThis query will provide the number of connection based on type.\n\n```sql\nSELECT count(*),\n    state\nFROM pg_stat_activity\nGROUP BY state;\n```\n\nIf you see idle connections is above 20, it is recommended to explore using PgBouncer.\n\n#### Query size of specific table\n\nWill give you the size of the specific relation you pass in.\n\n```sql\nSELECT pg_relation_size('table_name');\n\n-- For prettier formatting you can wrap with:\n\nSELECT pg_size_pretty(pg_relation_size('table_name'));\n```\n\n#### Query all relation sizes\n\nWill report on all table sizes in descending order\n\n```sql\nSELECT relname AS relation,\n       pg_size_pretty (\n         pg_total_relation_size (C .oid)\n       ) AS total_size\nFROM pg_class C\nLEFT JOIN pg_namespace N ON (N.oid = C .relnamespace)\nWHERE nspname NOT IN (\n        'pg_catalog',\n        'information_schema'\n      )\n  AND C .relkind <> 'i'\n  AND nspname !~ '^pg_toast'\n  ORDER BY pg_total_relation_size (C .oid) DESC\n```\n\n#### Check for unused indexes\n\nWill return the unused indexes in descending order of size. Keep in mind you want to also check replicas before dropping indexes.\n\n```sql\nSELECT schemaname || '.' || relname AS table,\n       indexrelname AS index,\n       pg_size_pretty(pg_relation_size(i.indexrelid)) AS \"index size\",\n       idx_scan as \"index scans\"\nFROM pg_stat_user_indexes ui\nJOIN pg_index i ON ui.indexrelid = i.indexrelid\nWHERE NOT indisunique\n  AND idx_scan < 50\n  AND pg_relation_size(relid) > 5 * 8192\nORDER BY \n  pg_relation_size(i.indexrelid) / nullif(idx_scan, 0) DESC NULLS FIRST,\n  pg_relation_size(i.indexrelid) DESC;\n```\n\n#### Get approximate counts for a table\n\nWill return the approximate count for a table based on PostgreSQL internal statistics. Useful for large tables where performing a \\`SELECT count(*)\\` is costly on performance.\n\n```sql\nSELECT reltuples::numeric as count\nFROM pg_class\nWHERE relname='table_name';\n```\n\n#### Non-blocking index creation\n\nAdding \\`CONCURRENTLY\\` during index creation, while not permitted in a transaction, will not hold a lock on the table while creating your index.\n\n```sql\nCREATE INDEX CONCURRENTLY foobar ON foo (bar);\n```\n\n### Replace nulls with other value\n\nCoalesce will use the value and if the value is null display your specified string.\n\n```sql\nSELECT id, \n       coalesce(ip, 'no IP') \nFROM logs;\n```\n\nYou can supply two columns as well prior to your replacement value and the function will use first not null value.\n\n### Import Schema with Mapping a Foreign Data Wrapper (FDW)\n\nImport foreign schema creates foreign tables representing those from the foreign server.\n\n```sql\nIMPORT FOREIGN SCHEMA \"public\";\n```\n\nYou can `IMPORT FOREIGN SCHEMA` when mapping a foreign data wrapper to save you from building a new one\n\n### Generate data with generate_series\n\nGenerates values from the start to the end values supplied based on the interval. Values can be numbers or timestamps. Can be used in a FROM or JOIN clause or CTE. Commonly used when building charts and reports that require all dates to be filled.\n\n```sql\nSELECT * FROM\ngenerate_series(now() - '3 month'::interval, now(), '1 day');\n```\n\n### Round dates with date_trunc\n\nWill truncate the date to the specified level of precision. Some example precision levels include: month, week, day, hour, minute.\n\n```sql\nSELECT date_trunc('day', now());\n```\n\n### Perform time math with intervals\n\nYou can add or subtract specific amounts of time of a timestamp by casting the value you want as an interval.\n\n```sql\nSELECT now() - '1 month'::interval;\n```\n\n### Make your session rest a bit\n\nThis function will make your session sleep for 2.5 seconds. Useful in any testing tool executing a script in a given loop where you want to pause a bit between iterations, as an example.\n\n```sql\nselect pg_sleep(2.5);\n```\n\n## PL/pgSQL\n\n### Wipe Schema Tables\n\n```sql\n-- DROP FUNCTION IF EXISTS idb.wipe_staging();\nCREATE OR REPLACE FUNCTION idb.wipe_staging()\nRETURNS TABLE(staging_schema text, deleted_tables integer) \nLANGUAGE 'plpgsql'\nCOST 100\nVOLATILE PARALLEL UNSAFE\nROWS 1000\nAS $BODY$\n#variable_conflict use_column\nDECLARE\n  staging_schema TEXT;\n  table_name TEXT;\n  deleted_tables INTEGER := 0;\nBEGIN\nstaging_schema = (select 'stg_' || user)::text;\nFOR table_name IN (\n    SELECT table_name \n    FROM information_schema.tables\n    WHERE table_schema = staging_schema\n)\nLOOP\nEXECUTE format('DROP TABLE %I.%I CASCADE', staging_schema, table_name );\ndeleted_tables := deleted_tables + 1;\nEND LOOP;\nRETURN query select staging_schema, deleted_tables;\nEND;\n$BODY$;\nALTER FUNCTION idb.wipe_staging()\n    OWNER TO envdb_dm;\n```\n\n## psql\n\n[Cheat sheet](https://quickref.me/postgres)\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n\nf = \"../../../static/development/commands.xlsx\"\n\nt4 = pd.read_excel(f, sheet_name=\"psql-commands\")\nt4.to_html(index=False)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th>Command</th>\\n      <th>Detail</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <td>sudo -s postgres psql</td>\\n      <td>Connect to PostgreSQL as admin</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\l</td>\\n      <td>List all databases</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\c postgres</td>\\n      <td>Connect to the database named postgres</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\q</td>\\n      <td>Disconnect</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -d mydb</td>\\n      <td>Connecting to database</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -U john mydb</td>\\n      <td>Connecting as a specific user</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -h localhost -p 5432 mydb</td>\\n      <td>Connecting to a host/port</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -U admin -h 192.168.1.5 -p 2506 -d mydb</td>\\n      <td>Connect remote PostgreSQL</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -W mydb</td>\\n      <td>Force password</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -c \\'\\\\c postgres\\' -c \\'\\\\dt\\'</td>\\n      <td>Execute a SQL query or command</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -c \"\\\\l+\" -H postgres &gt; database.html</td>\\n      <td>Generate HTML report</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -l</td>\\n      <td>List all databases</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\dt</td>\\n      <td>Show all tables in a database</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# mydb -f file.sql</td>\\n      <td>Execute commands from a file</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# -V</td>\\n      <td>Print the psql version</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\df &lt;schema&gt;</td>\\n      <td>List functions in schema</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\du</td>\\n      <td>Show current user permission</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\d &lt;table&gt;</td>\\n      <td>Describe table</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\d+ &lt;table&gt;</td>\\n      <td>Describe table with details</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\di</td>\\n      <td>List indexes</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\du</td>\\n      <td>List roles</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\ds</td>\\n      <td>List sequences</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\copy â€¦</td>\\n      <td>Import/export table</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\echo [string]</td>\\n      <td>Print string</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\i [file]</td>\\n      <td>Execute file</td>\\n    </tr>\\n    <tr>\\n      <td>postgres=# \\\\o [file]</td>\\n      <td>Export all results to file</td>\\n    </tr>\\n  </tbody>\\n</table>\n:::\n:::\n\n\n### Export table to CSV\n\n- `\\copy table TO '<path>' CSV`\n- `\\copy table(col1,col1) TO '<path>' CSV`\n- `\\copy (SELECT...) TO '<path>' CSV`\n  \n### Backup\n\nUse pg_dumpall to backup all databases\n\n`pg_dumpall -U postgres > all.sql`\n\nUse pg_dump to backup a database\n\n`pg_dump -d mydb -f mydb_backup.sql`\n\n- `-a` Â  Dump only the data, not the schema\n- `-s` Â  Dump only the schema, no data\n- `-c` Â  Drop database before recreating\n- `-C` Â  Create database before restoring\n- `-t` Â  Dump the named table(s) only\n- `-F` Â  Format (`c`: custom, `d`: directory, `t`: tar)\n\nUse `pg_dump -?` to get the full list of options\n\n### Restore\n\n`psql -U user mydb < mydb_backup.sql`\n\n#### pg_restore\n\n`pg_restore -d mydb mydb_backup.sql -c`\n\n- `-U   Specify a database user`\n- `-c   Drop database before recreating`\n- `-C   Create database before restoring`\n- `-e   Exit if an error has encountered`\n- `-F   Format (c: custom, d: directory, t: tar, p: plain text sql(default))`\n\nUse pg_restore -? to get the full list of options\n\n### Automatically log query time in psql\n\nWill automatically print the time it took to run a query from within psql. \\*Of note this is the round trip time not simply query execution time.\\*\n\n```bash\n\\timing\n```\n\nYou can save this in your `.psqlrc` to be a default setting\n\n### Autoformat query results in psql\n\nWill automatically reorganize the query output based on your terminal window for better readability.\n\n```bash\n\\x auto\n```\n\nYou can save this in your `.psqlrc` to be a default setting\n\n### Edit your psql queries in editor of your choice\n\nWill automatically open your last run query in your default `$EDITOR`. When you save and close it will execute that query.\n\n```bash\n\\e\n```\n\n### Set a value for nulls\n\nWill render the nulls as whatever character you specify. Handy for easier parsing of nulls vs. blank text.\n\n```bash\n\\pset null ðŸ‘»\n```\n\nYou can save this in your `.psqlrc` to be a default setting\n\n### Save your query history per database locally\n\nWill automatically save a history file for each \\*\\*DBNAME\\*\\*.\n\n```bash\n\\set HISTFILE ~/.psql_history- :DBNAME\n```\n\nYou can save this in your `.psqlrc` to be a default setting\n\n### Show queries issued by internal psql commands\n\nAdd \"-E\" (or --echo-hidden) option to psql in the command line. This option will display queries that internal psql commands generate (like \"\\\\dt mytable\"). This is a cool way to learn more about system catalogs, or reuse queries issued by psql in your own tool.\n\n```sql\npsql -E\n```\n\n### Get data back, and only the data\n\nAdd \"-qtA\" options to psql in the command line. Those options will have psql run in quiet mode (\"-q\"), return tuples only (\"-t\") in an unaligned fashion (\"-A\"). Combined with \"-c\" option to send a single query, it can be useful for your scripts if you want the data and only that back from Postgres. Returns one line per row.\n\n```sql\npsql -qtA\n```\n\n### Get results as an HTML table\n\nAdd \"-qtH\" options to psql in the command line. Those options will have psql run in quiet mode (\"-q\"), return tuples only (\"-t\") in an HTML table (\"-H\"). Combined with \"-c\" option to send a single query, can be a fast way to embed the result of a query in an HTML page.\n\n```sql\npsql -qtH\n```\n\n### Clear your psql screen\n\nWill clear your screen in current psql session\n\n```bash\n\\! clear\n```\n\n### Continually run a query with watch\n\nWill automatically run the last query every 2 seconds and display the output. You can also specify the query that will run after watch as well.\n\n```bash\n\\watch\n```\n\n### Rollback to previous statement on error when in interactive mode\n\nWhen you encounter an error when in interactive mode this will automatically rollback to just before the previous command, allowing you to continue working as you would expect.\n\n```sql\n\\set ON_ERROR_ROLLBACK interactive\n```\n\n### Export a CSV from directly in psql\n\nWhen providing the `--csv` value with a query, this command will run the specific query and return CSV to STDOUT.\n\n```sql\npsql <connection-string> --csv -c 'select * from test;'\n```\n\n### Run a query from a file in psql\n\nWill execute the specified file when inside psql.\n\n```sql\n\\i filename\n```\n\n### Provide clean border within psql\n\nWill give you a border around the output of your queries when in psql\n\n```sql\n\\pset border 2\n```\n\nYou can save this in your `.psqlrc` to be a default setting\n\n### Set linestyle to unicode\n\nChanges the linestyle to unicode, which when combined with above tip leads to much cleaner formatting\n\n```sql\n\\pset linestyle unicode\n```\n\nYou can save this in your `.psqlrc` to be a default setting\n\n",
    "supporting": [
      "sql_files"
    ],
    "filters": [],
    "includes": {}
  }
}